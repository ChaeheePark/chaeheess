**자연어처리**

자연어처리: 우리가 일상생활에서 사용하는 언어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일(음성인식, 내용요약, 번역, 사용자의 감성 분석, 텍스트 분류 작업, 챗봇 등)

머신 러닝 워크플로우

![image](https://user-images.githubusercontent.com/60170358/106356389-8f69d080-6342-11eb-8364-1922dfb72f46.png)

1) 수집 : 기계에 학습시켜야 할 데이터, 자연어 데이터(말뭉치, 코퍼스)를 수집하는 단계 (해커톤에서 준 데이터들 사용)

2) 점검 및 탐색 : 데이터를 점검하고 탐색하는 단계 (EDA) (해커톤에서 주어진 데이터들 사용)

3) 전처리 및 정제: 자연어처리에서는 토큰화, 정제, 정규화, 불용어 제거등

4) 모델링 및 훈련 : 머신러닝에 대한 코드를 작성하는 단계

- 적절한 머신 러닝 알고리즘을 선택하여 모델링이 끝났다면 전처리가 완료된 데이터를 머신 러닝 알고리즘을 통해 기계에게 학습시킴

5) 평가 : 테스터용 데이터로 성능을 평가(해커톤에서 진행할 부분)

6) 배포



**텍스트 전처리**

텍스트 전처리: 용도에 맞게 텍스트를 사전에 처리하는 작업

1) 토큰화 : 토큰이라 불리는 단위로 코퍼스를 나누는 작업

- 단어 토큰화: 토큰의 기준을 단어로 설정

  - ex) Time is an illusion. Lunchtime double so! -> "Time", "is", "an", "illustion", "Lunchtime", "double", "so"
  - 한국어는 띄어쓰기만으로는 단어 토큰을 구분하기는 어려움

- 토큰화 중 생기는 선택의 순간

  - 아포스트로피가 들어간 상황에서는 ? : library에 따라 다름

- 토큰화에서 고려해야할 사항

  - 구두점이나 특수문자를 단순 제외해서는 안됨
  - 줄임말이나 단어 내에 띄어쓰기가 있는 경우도 고려

- 문장 토큰화 : 토큰의 기준을 문장으로 설정, 문장 분류

  - 여러 방법중 마침표로 구분하는 방법을 단순하게 생각해볼 수 있음

  - NLTK 라이브러리는 단순히 마침표를 구분자로하여 문장을 구분하지 않음
  - 한국어는 kss 라이브러리를 사용

- 이진 분류기 : 문장 토큰화에서의 예외 상황을 발생시키는 마침표의 처리를 위해서 입력에 따라 두개의 클래스로 분류하는 이진분류기를 사용

  - 두개의 클래스는, 
    -  마침표(.)가 단어의 일부분일 경우. 즉, 마침표가 약어(abbreivation)로 쓰이는 경우
    - 마침표(.)가 정말로 문장의 구분자(boundary)일 경우

- 한국어에서의 토큰화의 어려움

  - 한국어는 교착어라서 단어 토큰화와 유사한 형태를 얻으려면 어절 토큰화가 아니라 형태소 토큰화를 수행해야 함
  - 띄어쓰기가 잘 지켜지지 않음

- 품사 태깅 : 품사에 따라서 단어의 의미가 달라짐

- **한국어 토큰화** : koNLPy 파이썬 패키지를 사용해서 Okt, kkma 로 토큰화를 진행할 수 있다!!

  

2) 정제 및 정규화 : 용도에 맞게 토큰을 분류하는 작업 전 후에는 텍스트 데이터를 용도에 맞게 정제 및 정규화 하는 일

- 정제(cleaning) : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거

- 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만듬

  --방법--

- 규칙에 기반한 표기가 다른 단어들의 통합
  - ex) USA, US는 같은 의미를 가지므로 하나의 단어로 정규화 할 수 있음
- 대, 소문자 통합
- 불필요한 단어의 제거
  - 등장 빈도가 적은 단어
  - 길이가 짧은 단어(영어에서만)
- 정규표현식



3) 어간 추출과 표제어 추출

- 표제어 추출 : 표제어란 기본 사전형 단어이고 표제어 추출을 하는 가장 섬세한 방법은 형태학적 파싱을 먼저 진행해야 함

  - 어간 : 단어의 의미를 담고 있는 단어의 핵심 부분
  - 접사: 단어의 추가적인 의미를 주는 부분
  - 이 두가지 구성요소를 분리함(NLTK-WordNetLemmatizer)

- 어간 추출:  형태학적 분석을 단순화한 버전으로 섬세한 작업은 아니기 때문에 어간 추출 후 나오는 단어는 사전에 존재하지 않는 단어 일 수 있음, 또한 목적에 어긋난 단어가 추출 될 수 있음

- 한국어에서의 어간 추출

- | 언       | 품사               |
  | :------- | :----------------- |
  | 체언     | 명사, 대명사, 수사 |
  | 수식언   | 관형사, 부사       |
  | 관계언   | 조사               |
  | 독립언   | 감탄사             |
  | **용언** | **동사, 형용사**   |



4) 불용어: 갖고있는 데이터에서 유의미한 단어 토큰을 선별하기 위해 큰 의미가 없는 단어 토큰을 제거하는 작업

- 한국어에서 불용어 제거하기: 간단하게는 토큰화 후에 조사, 접속사 등을 제거함



5) 정규 표현식

- 정규 표현식 문법과 모듈 함수: 파이썬에서 정규표현식 모듈 re를 지원하므로 이를 이용하면 특정 규칙이 있는 텍스트 데이터를 빠르게 정제할 수 있음

  - 정규 표현식 문법

  - | 특수 문자      | 설명                                                         |
    | :------------- | :----------------------------------------------------------- |
    | .              | 한 개의 임의의 문자를 나타냅니다. (줄바꿈 문자인 \n는 제외)  |
    | ?              | 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있습니다. (문자가 0개 또는 1개) |
    | *              | 앞의 문자가 무한개로 존재할 수도 있고, 존재하지 않을 수도 있습니다. (문자가 0개 이상) |
    | +              | 앞의 문자가 최소 한 개 이상 존재합니다. (문자가 1개 이상)    |
    | ^              | 뒤의 문자로 문자열이 시작됩니다.                             |
    | $              | 앞의 문자로 문자열이 끝납니다.                               |
    | {숫자}         | 숫자만큼 반복합니다.                                         |
    | {숫자1, 숫자2} | 숫자1 이상 숫자2 이하만큼 반복합니다. ?, *, +를 이것으로 대체할 수 있습니다. |
    | {숫자,}        | 숫자 이상만큼 반복합니다.                                    |
    | [ ]            | 대괄호 안의 문자들 중 한 개의 문자와 매치합니다. [amk]라고 한다면 a 또는 m 또는 k 중 하나라도 존재하면 매치를 의미합니다. [a-z]와 같이 범위를 지정할 수도 있습니다. [a-zA-Z]는 알파벳 전체를 의미하는 범위이며, 문자열에 알파벳이 존재하면 매치를 의미합니다. |
    | [^문자]        | 해당 문자를 제외한 문자를 매치합니다.                        |
    | l              | AlB와 같이 쓰이며 A 또는 B의 의미를 가집니다.                |

    | 문자 규칙 | 설명                                                         |
    | :-------- | :----------------------------------------------------------- |
    | \\        | 역 슬래쉬 문자 자체를 의미합니다                             |
    | \d        | 모든 숫자를 의미합니다. [0-9]와 의미가 동일합니다.           |
    | \D        | 숫자를 제외한 모든 문자를 의미합니다. [^0-9]와 의미가 동일합니다. |
    | \s        | 공백을 의미합니다. [ \t\n\r\f\v]와 의미가 동일합니다.        |
    | \S        | 공백을 제외한 문자를 의미합니다. [^ \t\n\r\f\v]와 의미가 동일합니다. |
    | \w        | 문자 또는 숫자를 의미합니다. [a-zA-Z0-9]와 의미가 동일합니다. |
    | \W        | 문자 또는 숫자가 아닌 문자를 의미합니다. [^a-zA-Z0-9]와 의미가 동일합니다. |

  - 정규표현식 모듈 함수

  - | 모듈 함수     | 설명                                                         |
    | :------------ | :----------------------------------------------------------- |
    | re.compile()  | 정규표현식을 컴파일하는 함수입니다. 다시 말해, 파이썬에게 전해주는 역할을 합니다. 찾고자 하는 패턴이 빈번한 경우에는 미리 컴파일해놓고 사용하면 속도와 편의성면에서 유리합니다. |
    | re.search()   | 문자열 전체에 대해서 정규표현식과 매치되는지를 검색합니다.   |
    | re.match()    | 문자열의 처음이 정규표현식과 매치되는지를 검색합니다.        |
    | re.split()    | 정규 표현식을 기준으로 문자열을 분리하여 리스트로 리턴합니다. |
    | re.findall()  | 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열을 찾아서 리스트로 리턴합니다. 만약, 매치되는 문자열이 없다면 빈 리스트가 리턴됩니다. |
    | re.finditer() | 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열에 대한 이터레이터 객체를 리턴합니다. |
    | re.sub()      | 문자열에서 정규 표현식과 일치하는 부분에 대해서 다른 문자열로 대체합니다. |

- 정규 표현식 실습

  - ```python
    import re
    r=re.compile("a,c") #'.'은 한개의 임의의 문자를 나타냄
    r.search("kkk") #아무런 결과도 출력되지 않음
    r.search("abc") #<_sre.SRE_Match object; span=(0, 3), match='abc'>  
    
    r=re.comile("ab?c") #'?'은 앞의 문자가 존재할 수 있고, 존재하지 않을 수도 있는 경우를 나타냄
    r.search("abbc") #아무런 결과도 출력되지 않음
    r.search("abc") #<_sre.SRE_Match object; span=(0, 3), match='abc'>  
    
    r=re.compile("ab*c") #'*'은 바로 앞의 문자가 0개 이상일 경우를 나타냄
    r.search("a") #아무런 결과도 출력되지 않음
    r.search("ac") #<_sre.SRE_Match object; span=(0, 2), match='ac'>  
    
    r=re.compile("ab+c") #'+'은 바로 앞의 문자가 1개 이상일 경우를 나타냄
    r.search("ac") #아무런 결과도 출력되지 않음
    r.search("abbbbc") #<_sre.SRE_Match object; span=(0, 6), match='abbbbc'>  
    
    r=re.compile("^a") #'^'는 시작되는 글자를 지정
    r.search("bbc") #아무런 결과도 출력되지 않음
    
    r=re.compile("[abc]") #[abc]== [a-c], []안에 문자들을 넣으면 그 문자들 중 한 개의 문자와 매치라는 의미
    r.search("zzz") #아무런 결과도 출력되지 않음
    r.search("baac") #<_sre.SRE_Match object; span=(0, 1), match='b'>
    ```

- 정규 표현식 텍스트 전처리 예제

  ```python
  import re
  
  text = """100 John    PROF
  101 James   STUD
  102 Mac   STUD"""  
  
  re.split('\s+', text) #['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']
  re.findall('\d+',text) #['100', '101', '102]
  re.findall('[A-Z]',text) #['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']
  re.findall('[A-Z]{4}',text) #['PROF', 'STUD', 'STUD']
  re.findall('[A-Z][a-z]+',text) #['John', 'James', 'Mac'] 
  
  ```



6) 정수 인코딩: 자연어처리에서 텍스트를 숫자로 바꾸는 여러가지 기법, 단어와 맵핑되는 고유한 정수, 표현으로 index를 부여

- 정수 인코딩:  text에서 빈도수가 높은 순서대로 index를 부여
- keras의 텍스트 전처리



 7)  패딩: 자연어 처리를 하다 보면 각 문장은 서로 길이가 다를 수 있는데 기계는 길이가 전부 동일한 문서들에 대해서는 하나의 행렬로 보고, 한꺼번에 묶어서 처리할 수 있음, 즉 병렬 연산을 위해 여러문장의 길이를 임의로 동일하게 맞춰주는 작업이 필요함



8) 원-핫 인코딩 : 컴퓨터는 문자보다는 숫자를 더 잘 처리할 수 있는데, 이를 위해 자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법중 기본적인 기법

- 단어집합 : 원핫 인코딩을 위해 먼저 해야할 일, 텍스트의 모든 단어를 중복을 허용하지 않고 모아놓음
- 1) 각 단어에 고유한 인덱스를 부여합니다. (정수 인코딩)
- 2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다.
- 한계 : 단어의 개수가 늘어날 수록, 벡터를 저장하기 위해 필요한 공간이 늘어난다는 단점이 있고 단어의 유사도를 표현하지 못한다는 단점이 있음



9) 데이터의 분리



10) 한국어 전처리 패키지

- PykoSpacing
- Py-Hanspell
- SOYNLP
- Customized KoNLPy
